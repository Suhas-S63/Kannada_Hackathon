{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/pytesseract'"
      ],
      "metadata": {
        "id": "9zuynC41NPzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! sudo apt install tesseract-ocr\n",
        "! apt install libtesseract-dev\n",
        "! pip install pytesseract\n",
        "! pip install pymupdf\n",
        "! pip install tesseract\n",
        "! pip install easyocr\n",
        "! pip install paddleocr\n",
        "! pip install paddlepaddle"
      ],
      "metadata": {
        "id": "MLxXjNC8NGK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def clear_directory(directory_path):\n",
        "    if os.path.exists(directory_path):\n",
        "        for filename in os.listdir(directory_path):\n",
        "            file_path = os.path.join(directory_path, filename)\n",
        "\n",
        "            try:\n",
        "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                    os.unlink(file_path)\n",
        "                elif os.path.isdir(file_path):\n",
        "                    shutil.rmtree(file_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
        "    else:\n",
        "        os.makedirs(directory_path)\n",
        "\n",
        "clear_directory(\"output/pdf_images\")\n",
        "clear_directory(\"output/preprocessed_images\")\n",
        "clear_directory(\"output/ocr_texts\")\n",
        "clear_directory(\"output/cropped_images\")\n"
      ],
      "metadata": {
        "id": "lJqb0wolQeRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import fitz\n",
        "import pytesseract\n",
        "import easyocr\n",
        "import paddleocr\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Create necessary directories\n",
        "os.makedirs(\"output/pdf_images\", exist_ok=True)\n",
        "os.makedirs(\"output/preprocessed_images\", exist_ok=True)\n",
        "os.makedirs(\"output/ocr_texts\", exist_ok=True)\n",
        "os.makedirs(\"output/cropped_images\", exist_ok=True)\n",
        "\n",
        "# OCR Model Types\n",
        "class ModelTypes:\n",
        "    Tesseract = \"tesseract\"\n",
        "    EasyOCR = \"easyocr\"\n",
        "    PaddleOCR = \"paddleocr\"\n",
        "\n",
        "# Step 1: Image Extraction from PDF and Images\n",
        "def extract_images(file_path):\n",
        "    if file_path.lower().endswith('.pdf'):\n",
        "        pdf_to_images(file_path)\n",
        "    else:\n",
        "        process_image(file_path)\n",
        "\n",
        "def pdf_to_images(pdf_path):\n",
        "    pdf_doc = fitz.open(pdf_path)\n",
        "    for page_num in range(len(pdf_doc)):\n",
        "        page = pdf_doc.load_page(page_num)\n",
        "        pix = page.get_pixmap(dpi=300)\n",
        "        img_path = f\"output/pdf_images/{page_num + 1:02d}_page.jpg\"\n",
        "        pix.save(img_path)\n",
        "        print(f\"Extracted and saved: {img_path}\")\n",
        "    pdf_doc.close()\n",
        "\n",
        "def process_image(img_path):\n",
        "    if img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if image is None:\n",
        "            print(f\"Error: Unable to load image: {img_path}\")\n",
        "            return\n",
        "        preprocessed_image = preprocess_image(image)\n",
        "        preprocessed_path = f\"output/preprocessed_images/{os.path.basename(img_path)}\"\n",
        "        cv2.imwrite(preprocessed_path, preprocessed_image)\n",
        "        print(f\"Processed and saved: {preprocessed_path}\")\n",
        "\n",
        "# Step 2: Preprocess the Image\n",
        "def preprocess_image(image):\n",
        "    image = cv2.bitwise_not(image)  # Invert colors for better OCR\n",
        "    blurred = cv2.GaussianBlur(image, (9, 9), 0)\n",
        "    sharp_image = image_sharpen(blurred)\n",
        "    thresholded_image = image_thresholding(sharp_image)\n",
        "    return thresholded_image\n",
        "\n",
        "def image_sharpen(image):\n",
        "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
        "    return cv2.filter2D(image, -1, kernel)\n",
        "\n",
        "def image_thresholding(image):\n",
        "    _, binary_image = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "    return binary_image\n",
        "\n",
        "# Step 3: Crop Images and Remove Duplicates\n",
        "def crop_and_remove_duplicates(preprocessed_dir=\"output/preprocessed_images\"):\n",
        "    for img_file in os.listdir(preprocessed_dir):\n",
        "        img_path = os.path.join(preprocessed_dir, img_file)\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if image is None:\n",
        "            print(f\"Error: Unable to load image: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        cropped_images = []\n",
        "        cropped_images += crop_image_by_rows(image)   # Crop by rows based on criteria\n",
        "        cropped_images += crop_image_by_columns(image)  # Crop by columns based on vertical white space\n",
        "\n",
        "        unique_crops = remove_duplicates(cropped_images)\n",
        "\n",
        "        for i, unique_crop in enumerate(unique_crops):\n",
        "            crop_output_path = f\"output/cropped_images/{os.path.basename(img_file)}_crop_{i}.jpg\"\n",
        "            cv2.imwrite(crop_output_path, unique_crop)\n",
        "            print(f\"Saved cropped image: {crop_output_path}\")\n",
        "\n",
        "def crop_image_by_rows(image):\n",
        "    h, w = image.shape[:2]\n",
        "    row_height = h // 4  # Example: Divide image into 4 horizontal parts\n",
        "    cropped_images = []\n",
        "\n",
        "    for i in range(0, h, row_height):\n",
        "        crop = image[i:i + row_height, 0:w]\n",
        "        if crop.size > 0:  # Check if the crop is non-empty\n",
        "            cropped_images.append(crop)\n",
        "\n",
        "    return cropped_images\n",
        "\n",
        "def crop_image_by_columns(image):\n",
        "    h, w = image.shape[:2]\n",
        "    cropped_images = []\n",
        "\n",
        "    # Convert image to binary to find white spaces\n",
        "    _, binary_image = cv2.threshold(image, 200, 255, cv2.THRESH_BINARY)\n",
        "    vertical_sum = np.sum(binary_image, axis=0)  # Sum along the columns\n",
        "    column_indices = np.where(vertical_sum < (h * 255 * 0.1))[0]  # Find columns with white space\n",
        "\n",
        "    # Group indices into segments\n",
        "    last_index = -1\n",
        "    start_index = -1\n",
        "    for idx in column_indices:\n",
        "        if start_index == -1:  # Start a new segment\n",
        "            start_index = idx\n",
        "        if last_index != -1 and idx > last_index + 1:  # End the current segment\n",
        "            crop = image[0:h, start_index:last_index + 1]\n",
        "            cropped_images.append(crop)\n",
        "            start_index = idx  # Start a new segment\n",
        "        last_index = idx\n",
        "\n",
        "    # Handle the last segment if applicable\n",
        "    if start_index != -1 and last_index != -1 and start_index < last_index:\n",
        "        crop = image[0:h, start_index:last_index + 1]\n",
        "        cropped_images.append(crop)\n",
        "\n",
        "    return cropped_images\n",
        "\n",
        "def remove_duplicates(image_list):\n",
        "    unique_images = []\n",
        "    for i, img1 in enumerate(image_list):\n",
        "        is_unique = True\n",
        "\n",
        "        img1_resized = cv2.resize(img1, (300, 300))\n",
        "\n",
        "        for img2 in unique_images:\n",
        "            img2_resized = cv2.resize(img2, (300, 300))\n",
        "            score, _ = ssim(img1_resized, img2_resized, full=True)\n",
        "\n",
        "            if score > 0.95:  # Similarity threshold\n",
        "                is_unique = False\n",
        "                break\n",
        "\n",
        "        if is_unique:\n",
        "            unique_images.append(img1)\n",
        "\n",
        "    return unique_images\n",
        "\n",
        "# Step 4: Perform OCR on Preprocessed Images\n",
        "def perform_ocr_on_images(preprocessed_dir=\"output/preprocessed_images\", model_type=ModelTypes.Tesseract):\n",
        "    for img_file in os.listdir(preprocessed_dir):\n",
        "        img_path = os.path.join(preprocessed_dir, img_file)\n",
        "        text = perform_ocr(img_path, model_type=model_type)\n",
        "        if text:\n",
        "            output_text_path = f\"output/ocr_texts/{os.path.basename(img_path)}.txt\"\n",
        "            with open(output_text_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(text)\n",
        "            print(f\"Saved OCR text: {output_text_path}\")\n",
        "\n",
        "def perform_ocr(image_path, model_type):\n",
        "    if model_type == ModelTypes.Tesseract:\n",
        "        return perform_ocr_tesseract(image_path)\n",
        "    elif model_type == ModelTypes.EasyOCR:\n",
        "        return perform_ocr_easyocr(image_path)\n",
        "    elif model_type == ModelTypes.PaddleOCR:\n",
        "        return perform_ocr_paddleocr(image_path)\n",
        "    else:\n",
        "        print(\"Unsupported OCR model type.\")\n",
        "        return \"\"\n",
        "\n",
        "def perform_ocr_tesseract(image_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if image is None:\n",
        "        print(f\"Error: Unable to load image: {image_path}\")\n",
        "        return \"\"\n",
        "    return pytesseract.image_to_string(image, config='--oem 3 --psm 6 -l kan+eng')\n",
        "\n",
        "def perform_ocr_easyocr(image_path):\n",
        "    reader = easyocr.Reader(['en', 'kn'])  # English and Kannada\n",
        "    results = reader.readtext(image_path)\n",
        "    text = ' '.join([result[1] for result in results])\n",
        "    return text\n",
        "\n",
        "def perform_ocr_paddleocr(image_path):\n",
        "    ocr = paddleocr.OCR()  # Initialize PaddleOCR\n",
        "    results = ocr.ocr(image_path, cls=True)\n",
        "    text = ' '.join([line[1][0] for line in results[0]])\n",
        "    return text\n",
        "\n",
        "def preprocess_images(image_dir=\"output/pdf_images\"):\n",
        "    for img_file in os.listdir(image_dir):  # Iterate through images in the specified directory\n",
        "        img_path = os.path.join(image_dir, img_file)\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if image is None:\n",
        "            print(f\"Error: Unable to load image: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        # Call the unified preprocessing logic\n",
        "        preprocessed_image = preprocess_image(image)  # Preprocess using the common function\n",
        "        save_preprocessed_image(preprocessed_image, img_file)  # Save preprocessed image\n",
        "\n",
        "def save_preprocessed_image(preprocessed_image, img_file):\n",
        "    preprocessed_path = f\"output/preprocessed_images/{img_file}\"\n",
        "    cv2.imwrite(preprocessed_path, preprocessed_image)\n",
        "\n",
        "# Main Driver Function\n",
        "def main(file_path, model_type=ModelTypes.Tesseract):\n",
        "    extract_images(file_path)          # Step 1: Extract images from PDF or normal images\n",
        "    preprocess_images()                # Step 2: Preprocess images\n",
        "    crop_and_remove_duplicates()       # Step 3: Crop and remove duplicates\n",
        "    perform_ocr_on_images(model_type=model_type)  # Step 4: Perform OCR on preprocessed images\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"/content/02_page.jpg\"  # Replace with the path to your PDF or image\n",
        "    selected_model = ModelTypes.EasyOCR  # Choose the OCR model type (Tesseract, EasyOCR, PaddleOCR)\n",
        "    main(file_path, model_type=selected_model)  # Run the process\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V5dB2StWZoN",
        "outputId": "74ddc064-7114-450a-c71e-3a8078a8d4d0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed and saved: output/preprocessed_images/02_page.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_0.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_1.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_2.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_3.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_4.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_5.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_6.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_7.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_8.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_9.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_10.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_11.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_12.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_13.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_14.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_15.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_16.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_17.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_18.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_19.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_20.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_21.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_22.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_23.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_24.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_25.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_26.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_27.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_28.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_29.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_30.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_31.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_32.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_33.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_34.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_35.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_36.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_37.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_38.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_39.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_40.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_41.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_42.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_43.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_44.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_45.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_46.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_47.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_48.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_49.jpg\n",
            "Saved cropped image: output/cropped_images/02_page.jpg_crop_50.jpg\n",
            "Saved OCR text: output/ocr_texts/02_page.jpg.txt\n"
          ]
        }
      ]
    }
  ]
}